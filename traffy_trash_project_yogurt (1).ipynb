{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b52a98a",
   "metadata": {},
   "source": [
    "\n",
    "# Smart environment Hotspot & Risk Prediction using Traffy Fondue\n",
    "\n",
    "This notebook is a **full project pipeline** template for a environment-related data project using **Traffy Fondue** data.\n",
    "\n",
    "- Uses Traffy Fondue complaints data\n",
    "- Adds external data (you plug in your own API/scraping)\n",
    "- Includes:\n",
    "  - Data Engineering (cleaning + aggregation)\n",
    "  - Machine Learning (predict environment complaints)\n",
    "  - Visualization (time trends, optional map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7f2a0d",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "27c1fc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Config & Imports ===\n",
    "\n",
    "# If running in a fresh environment, you may need to install:\n",
    "# !pip install pandas numpy scikit-learn matplotlib seaborn requests\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Optional: for geospatial visualization\n",
    "try:\n",
    "    import geopandas as gpd\n",
    "except ImportError:\n",
    "    gpd = None\n",
    "    print(\"geopandas not installed. Geospatial choropleth will be skipped unless installed.\")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "sns.set(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207bce10",
   "metadata": {},
   "source": [
    "## 1. Load Traffy Fondue Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "dd506b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Traffy shape: (787026, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>type</th>\n",
       "      <th>organization</th>\n",
       "      <th>comment</th>\n",
       "      <th>photo</th>\n",
       "      <th>photo_after</th>\n",
       "      <th>coords</th>\n",
       "      <th>address</th>\n",
       "      <th>subdistrict</th>\n",
       "      <th>district</th>\n",
       "      <th>province</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>state</th>\n",
       "      <th>star</th>\n",
       "      <th>count_reopen</th>\n",
       "      <th>last_activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-FYJTFP</td>\n",
       "      <td>{ความสะอาด}</td>\n",
       "      <td>เขตบางซื่อ</td>\n",
       "      <td>ขยะเยอะ</td>\n",
       "      <td>https://storage.googleapis.com/traffy_public_b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.53084,13.81865</td>\n",
       "      <td>12/14 ถนน กรุงเทพ- นนทบุรี แขวง บางซื่อ เขตบาง...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>2021-09-03 12:51:09.453003+00</td>\n",
       "      <td>เสร็จสิ้น</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-06-04 15:34:14.609206+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-CGPMUN</td>\n",
       "      <td>{น้ำท่วม,ร้องเรียน}</td>\n",
       "      <td>เขตประเวศ,ฝ่ายโยธา เขตประเวศ</td>\n",
       "      <td>น้ำท่วมเวลาฝนตกและทะลุเข้าบ้านเดือดร้อนมากทุกๆ...</td>\n",
       "      <td>https://storage.googleapis.com/traffy_public_b...</td>\n",
       "      <td>https://storage.googleapis.com/traffy_public_b...</td>\n",
       "      <td>100.66709,13.67891</td>\n",
       "      <td>189 เฉลิมพระเกียรติ ร.9 แขวง หนองบอน เขต ประเว...</td>\n",
       "      <td>หนองบอน</td>\n",
       "      <td>ประเวศ</td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>2021-09-19 14:56:08.924992+00</td>\n",
       "      <td>เสร็จสิ้น</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-06-21 08:21:09.532782+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-7XATFA</td>\n",
       "      <td>{สะพาน}</td>\n",
       "      <td>เขตสาทร</td>\n",
       "      <td>สะพานลอยปรับปรุงไม่เสร็จตามกำหนด\\nปากซอย สาทร12</td>\n",
       "      <td>https://storage.googleapis.com/traffy_public_b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.52649,13.72060</td>\n",
       "      <td>191/1 ถนน สาทรเหนือ แขวง สีลม เขตบางรัก กรุงเท...</td>\n",
       "      <td>ยานนาวา</td>\n",
       "      <td>สาทร</td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>2021-09-26 05:03:52.594898+00</td>\n",
       "      <td>เสร็จสิ้น</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-06-06 01:17:12.272904+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-9U2NJT</td>\n",
       "      <td>{น้ำท่วม}</td>\n",
       "      <td>เขตบางซื่อ,ฝ่ายโยธา เขตบางซื่อ</td>\n",
       "      <td>น้ำท่วม</td>\n",
       "      <td>https://storage.googleapis.com/traffy_public_b...</td>\n",
       "      <td>https://storage.googleapis.com/traffy_public_b...</td>\n",
       "      <td>100.53099,13.81853</td>\n",
       "      <td>12/14 ถนน กรุงเทพ- นนทบุรี แขวง บางซื่อ เขตบาง...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>2021-10-14 10:45:27.713884+00</td>\n",
       "      <td>เสร็จสิ้น</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-09-08 08:35:43.784519+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-DVEWYM</td>\n",
       "      <td>{น้ำท่วม,ถนน}</td>\n",
       "      <td>เขตลาดพร้าว,ฝ่ายโยธา เขตลาดพร้าว</td>\n",
       "      <td>ซอยลาดพร้าววังหิน 75 ถนนลาดพร้าววังหิน แขวงลาด...</td>\n",
       "      <td>https://storage.googleapis.com/traffy_public_b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.59165,13.82280</td>\n",
       "      <td>702 ถ. ลาดพร้าววังหิน แขวงลาดพร้าว เขตลาดพร้าว...</td>\n",
       "      <td>ลาดพร้าว</td>\n",
       "      <td>ลาดพร้าว</td>\n",
       "      <td>กรุงเทพมหานคร</td>\n",
       "      <td>2021-12-09 12:29:08.408763+00</td>\n",
       "      <td>เสร็จสิ้น</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-08-12 07:18:44.884945+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ticket_id                 type                      organization  \\\n",
       "0  2021-FYJTFP          {ความสะอาด}                        เขตบางซื่อ   \n",
       "1  2021-CGPMUN  {น้ำท่วม,ร้องเรียน}      เขตประเวศ,ฝ่ายโยธา เขตประเวศ   \n",
       "2  2021-7XATFA              {สะพาน}                           เขตสาทร   \n",
       "3  2021-9U2NJT            {น้ำท่วม}    เขตบางซื่อ,ฝ่ายโยธา เขตบางซื่อ   \n",
       "4  2021-DVEWYM        {น้ำท่วม,ถนน}  เขตลาดพร้าว,ฝ่ายโยธา เขตลาดพร้าว   \n",
       "\n",
       "                                             comment  \\\n",
       "0                                            ขยะเยอะ   \n",
       "1  น้ำท่วมเวลาฝนตกและทะลุเข้าบ้านเดือดร้อนมากทุกๆ...   \n",
       "2    สะพานลอยปรับปรุงไม่เสร็จตามกำหนด\\nปากซอย สาทร12   \n",
       "3                                            น้ำท่วม   \n",
       "4  ซอยลาดพร้าววังหิน 75 ถนนลาดพร้าววังหิน แขวงลาด...   \n",
       "\n",
       "                                               photo  \\\n",
       "0  https://storage.googleapis.com/traffy_public_b...   \n",
       "1  https://storage.googleapis.com/traffy_public_b...   \n",
       "2  https://storage.googleapis.com/traffy_public_b...   \n",
       "3  https://storage.googleapis.com/traffy_public_b...   \n",
       "4  https://storage.googleapis.com/traffy_public_b...   \n",
       "\n",
       "                                         photo_after              coords  \\\n",
       "0                                                NaN  100.53084,13.81865   \n",
       "1  https://storage.googleapis.com/traffy_public_b...  100.66709,13.67891   \n",
       "2                                                NaN  100.52649,13.72060   \n",
       "3  https://storage.googleapis.com/traffy_public_b...  100.53099,13.81853   \n",
       "4                                                NaN  100.59165,13.82280   \n",
       "\n",
       "                                             address subdistrict  district  \\\n",
       "0  12/14 ถนน กรุงเทพ- นนทบุรี แขวง บางซื่อ เขตบาง...         NaN       NaN   \n",
       "1  189 เฉลิมพระเกียรติ ร.9 แขวง หนองบอน เขต ประเว...     หนองบอน    ประเวศ   \n",
       "2  191/1 ถนน สาทรเหนือ แขวง สีลม เขตบางรัก กรุงเท...     ยานนาวา      สาทร   \n",
       "3  12/14 ถนน กรุงเทพ- นนทบุรี แขวง บางซื่อ เขตบาง...         NaN       NaN   \n",
       "4  702 ถ. ลาดพร้าววังหิน แขวงลาดพร้าว เขตลาดพร้าว...    ลาดพร้าว  ลาดพร้าว   \n",
       "\n",
       "        province                      timestamp      state  star  \\\n",
       "0  กรุงเทพมหานคร  2021-09-03 12:51:09.453003+00  เสร็จสิ้น   NaN   \n",
       "1  กรุงเทพมหานคร  2021-09-19 14:56:08.924992+00  เสร็จสิ้น   4.0   \n",
       "2  กรุงเทพมหานคร  2021-09-26 05:03:52.594898+00  เสร็จสิ้น   NaN   \n",
       "3  กรุงเทพมหานคร  2021-10-14 10:45:27.713884+00  เสร็จสิ้น   NaN   \n",
       "4  กรุงเทพมหานคร  2021-12-09 12:29:08.408763+00  เสร็จสิ้น   5.0   \n",
       "\n",
       "   count_reopen                  last_activity  \n",
       "0             0  2022-06-04 15:34:14.609206+00  \n",
       "1             0  2022-06-21 08:21:09.532782+00  \n",
       "2             0  2022-06-06 01:17:12.272904+00  \n",
       "3             0  2022-09-08 08:35:43.784519+00  \n",
       "4             0  2022-08-12 07:18:44.884945+00  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('bangkok_traffy.csv')\n",
    "print(\"Raw Traffy shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bcf918",
   "metadata": {},
   "source": [
    "## 2. Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "30cf9c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows after province filter: 439679\n",
      "Rows before removing NaN: 439679\n",
      "\n",
      "Missing values before dropna:\n",
      "ticket_id        0\n",
      "type             0\n",
      "coords           0\n",
      "comment          0\n",
      "organization     0\n",
      "district         0\n",
      "province         0\n",
      "timestamp        0\n",
      "state            0\n",
      "last_activity    0\n",
      "subdistrict      0\n",
      "dtype: int64\n",
      "\n",
      "Rows after removing NaN: 439679\n",
      "\n",
      "=== CLEANED DATA (HEAD) ===\n",
      "     ticket_id                 type              coords  \\\n",
      "1  2021-CGPMUN  {น้ำท่วม,ร้องเรียน}  100.66709,13.67891   \n",
      "2  2021-7XATFA              {สะพาน}  100.52649,13.72060   \n",
      "4  2021-DVEWYM        {น้ำท่วม,ถนน}  100.59165,13.82280   \n",
      "7  2021-8N9ZP8          {ความสะอาด}  100.64690,13.67083   \n",
      "9  2021-8BTWZB        {ท่อระบายน้ำ}  100.65440,13.68158   \n",
      "\n",
      "                                             comment  \\\n",
      "1  น้ำท่วมเวลาฝนตกและทะลุเข้าบ้านเดือดร้อนมากทุกๆ...   \n",
      "2    สะพานลอยปรับปรุงไม่เสร็จตามกำหนด\\nปากซอย สาทร12   \n",
      "4  ซอยลาดพร้าววังหิน 75 ถนนลาดพร้าววังหิน แขวงลาด...   \n",
      "7                  คนเอาขยะมาทิ้งจนกลายเป็นกองขยะค่ะ   \n",
      "9  ขอแจ้งเรื่องท่อระบายน้ำบนถนนในซอยเสียหาย เป็นร...   \n",
      "\n",
      "                                        organization  district       province  \\\n",
      "1                       เขตประเวศ,ฝ่ายโยธา เขตประเวศ    ประเวศ  กรุงเทพมหานคร   \n",
      "2                                            เขตสาทร      สาทร  กรุงเทพมหานคร   \n",
      "4                   เขตลาดพร้าว,ฝ่ายโยธา เขตลาดพร้าว  ลาดพร้าว  กรุงเทพมหานคร   \n",
      "7  เขตประเวศ,ฝ่ายเทศกิจ เขตประเวศ,ฝ่ายรักษาความสะ...    ประเวศ  กรุงเทพมหานคร   \n",
      "9                       เขตประเวศ,ฝ่ายโยธา เขตประเวศ    ประเวศ  กรุงเทพมหานคร   \n",
      "\n",
      "                       timestamp      state                  last_activity  \\\n",
      "1  2021-09-19 14:56:08.924992+00  เสร็จสิ้น  2022-06-21 08:21:09.532782+00   \n",
      "2  2021-09-26 05:03:52.594898+00  เสร็จสิ้น  2022-06-06 01:17:12.272904+00   \n",
      "4  2021-12-09 12:29:08.408763+00  เสร็จสิ้น  2022-08-12 07:18:44.884945+00   \n",
      "7  2021-12-18 14:50:52.437512+00  เสร็จสิ้น  2024-11-26 04:17:39.760344+00   \n",
      "9  2021-12-22 10:15:33.294829+00  เสร็จสิ้น   2022-06-20 13:12:04.99444+00   \n",
      "\n",
      "  subdistrict  \n",
      "1     หนองบอน  \n",
      "2     ยานนาวา  \n",
      "4    ลาดพร้าว  \n",
      "7     หนองบอน  \n",
      "9     หนองบอน  \n",
      "\n",
      "=== MISSING VALUES SUMMARY ===\n",
      "ticket_id        0\n",
      "type             0\n",
      "coords           0\n",
      "comment          0\n",
      "organization     0\n",
      "district         0\n",
      "province         0\n",
      "timestamp        0\n",
      "state            0\n",
      "last_activity    0\n",
      "subdistrict      0\n",
      "dtype: int64\n",
      "\n",
      "=== FINAL ROW COUNT: 439679 ===\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Read CSV ---\n",
    "df = pd.read_csv(\"bangkok_traffy.csv\")\n",
    "\n",
    "# --- Keep only selected columns ---\n",
    "keep_cols = [\n",
    "    \"ticket_id\", \"type\", \"coords\", \"comment\", \"organization\",\n",
    "    \"district\", \"province\", \"timestamp\", \"state\", \"last_activity\",\n",
    "    \"subdistrict\"\n",
    "]\n",
    "df = df[keep_cols]\n",
    "\n",
    "# ================================\n",
    "# DATA CLEANING\n",
    "# ================================\n",
    "\n",
    "# First, replace empty strings and \"{}\" with NaN BEFORE converting to string\n",
    "df = df.replace([\"\", \"{}\", \"nan\"], np.nan)\n",
    "\n",
    "# Now clean text columns (but don't convert NaN to string)\n",
    "text_cols = [\"subdistrict\", \"district\", \"province\", \"type\", \"comment\", \"organization\"]\n",
    "\n",
    "for col in text_cols:\n",
    "    # Only strip non-null values\n",
    "    df[col] = df[col].str.strip()\n",
    "\n",
    "# Remove rows with missing comments\n",
    "df = df[df[\"comment\"].notna()].copy()\n",
    "\n",
    "# --- Remove rows with missing required fields ---\n",
    "df = df[\n",
    "    df[\"district\"].notna() &\n",
    "    df[\"province\"].notna() &\n",
    "    df[\"type\"].notna()\n",
    "].copy()\n",
    "\n",
    "# ================================\n",
    "# FILTER ONLY กรุงเทพมหานคร + เสร็จสิ้น\n",
    "# ================================\n",
    "\n",
    "df = df[\n",
    "    (df[\"province\"] == \"กรุงเทพมหานคร\") &\n",
    "    (df[\"state\"] == \"เสร็จสิ้น\")\n",
    "].copy()\n",
    "\n",
    "print(f\"\\nRows after province filter: {len(df)}\")\n",
    "\n",
    "# ================================\n",
    "# REMOVE ALL ROWS WITH ANY NaN VALUES\n",
    "# ================================\n",
    "print(f\"Rows before removing NaN: {len(df)}\")\n",
    "print(\"\\nMissing values before dropna:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "print(f\"\\nRows after removing NaN: {len(df)}\")\n",
    "\n",
    "# ================================\n",
    "# FINAL OUTPUT\n",
    "# ================================\n",
    "print(\"\\n=== CLEANED DATA (HEAD) ===\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\n=== MISSING VALUES SUMMARY ===\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "print(f\"\\n=== FINAL ROW COUNT: {df.shape[0]} ===\")\n",
    "\n",
    "# # Optional: Save cleaned data\n",
    "df.to_csv(\"bangkok_traffy_cleaned.csv\", index=False)\n",
    "# print(\"\\n✅ Cleaned data saved to 'bangkok_traffy_cleaned.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83020822",
   "metadata": {},
   "source": [
    "## 3. Scrape District Area Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f68b1d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scraping กรุงเทพมหานคร ... https://e-report.energy.go.th/area/Bangkok.htm\n",
      "  → Using encoding: tis-620\n",
      "  → Headers: ['ลำดับ', 'อำเภอ/กิ่งอำเภอ', 'เนื้อที่ (ตร.กม.)']...\n",
      "  → Skipped 160 แขวง (sub-districts)\n",
      "  → Extracted 50 districts\n",
      "\n",
      "==================================================\n",
      "Total area records: 50\n"
     ]
    }
   ],
   "source": [
    "PROVINCES = {\n",
    "    \"กรุงเทพมหานคร\": \"Bangkok.htm\",\n",
    "}\n",
    "\n",
    "BASE_URL = \"https://e-report.energy.go.th/area/\"\n",
    "\n",
    "def fetch_html(url):\n",
    "    \"\"\"Fetch HTML with proper Thai encoding\"\"\"\n",
    "    resp = requests.get(url)\n",
    "    \n",
    "    for encoding in ['tis-620', 'windows-874', 'cp874']:\n",
    "        try:\n",
    "            resp.encoding = encoding\n",
    "            text = resp.text\n",
    "            if 'กรุงเทพ' in text or 'เนื้อที่' in text:\n",
    "                print(f\"  → Using encoding: {encoding}\")\n",
    "                return text\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    resp.encoding = resp.apparent_encoding\n",
    "    print(f\"  → Using auto-detected encoding: {resp.apparent_encoding}\")\n",
    "    return resp.text\n",
    "\n",
    "def parse_province_table(html, province_name):\n",
    "    \"\"\"Parse HTML table and extract area data\"\"\"\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    table = soup.find(\"table\")\n",
    "    if not table:\n",
    "        print(f\"[WARN] No table found for {province_name}\")\n",
    "        return []\n",
    "\n",
    "    header_cells = table.find(\"tr\").find_all([\"td\", \"th\"])\n",
    "    headers = [h.get_text(strip=True) for h in header_cells]\n",
    "    print(f\"  → Headers: {headers[:3]}...\")\n",
    "\n",
    "    area_idx = None\n",
    "    for i, h in enumerate(headers):\n",
    "        if \"เนื้อที่\" in h or \"พื้นที่\" in h:\n",
    "            area_idx = i\n",
    "            break\n",
    "\n",
    "    if area_idx is None:\n",
    "        print(f\"[WARN] No area column for {province_name}, skipping\")\n",
    "        return []\n",
    "\n",
    "    name_idx = 1\n",
    "    rows_data = []\n",
    "    skipped_count = 0\n",
    "    mueang_renamed = 0\n",
    "    \n",
    "    for tr in table.find_all(\"tr\")[1:]:\n",
    "        cols = [td.get_text(strip=True) for td in tr.find_all(\"td\")]\n",
    "        if len(cols) <= area_idx:\n",
    "            continue\n",
    "        district = cols[name_idx]\n",
    "        area = cols[area_idx]\n",
    "\n",
    "        if district == \"\" or area == \"\" or \"รวม\" in district.lower():\n",
    "            continue\n",
    "        \n",
    "        # Bangkok filter: only \"เขต\", skip \"แขวง\"\n",
    "        if province_name == \"กรุงเทพมหานคร\":\n",
    "            if district.startswith(\"แขวง\"):\n",
    "                skipped_count += 1\n",
    "                continue\n",
    "            if not district.startswith(\"เขต\"):\n",
    "                continue\n",
    "        \n",
    "        # Handle \"เมือง\" districts - append province name\n",
    "        # Remove common prefixes first to get clean province name\n",
    "        if district == \"เมือง\" or district == \"อำเภอเมือง\":\n",
    "            # Get short province name (without common prefixes)\n",
    "            province_short = province_name.replace(\"จังหวัด\", \"\").strip()\n",
    "            district = f\"เมือง{province_short}\"\n",
    "            mueang_renamed += 1\n",
    "            print(f\"  → Renamed 'เมือง' to '{district}'\")\n",
    "\n",
    "        rows_data.append({\n",
    "            \"province\": province_name,\n",
    "            \"district\": district,\n",
    "            \"area_km2\": area\n",
    "        })\n",
    "    \n",
    "    if province_name == \"กรุงเทพมหานคร\" and skipped_count > 0:\n",
    "        print(f\"  → Skipped {skipped_count} แขวง (sub-districts)\")\n",
    "    \n",
    "    if mueang_renamed > 0:\n",
    "        print(f\"  → Renamed {mueang_renamed} 'เมือง' districts\")\n",
    "\n",
    "    return rows_data\n",
    "\n",
    "# Scrape all provinces\n",
    "area_rows = []\n",
    "\n",
    "for prov_th, page in PROVINCES.items():\n",
    "    url = BASE_URL + page\n",
    "    print(f\"\\nScraping {prov_th} ... {url}\")\n",
    "    html = fetch_html(url)\n",
    "    rows = parse_province_table(html, prov_th)\n",
    "    area_rows.extend(rows)\n",
    "    print(f\"  → Extracted {len(rows)} districts\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Total area records: {len(area_rows)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17dff12",
   "metadata": {},
   "source": [
    "## 4. Fetch API Data (Population & Housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "2104c68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Creating new population_data.json\n",
      " - Loaded existing housing_data.json\n",
      "\n",
      "--- Fetching POPULATION: yymm 6501-6512, cc=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  STATUS: 200\n",
      "  RAW (first 200 chars): [{\"lstrLevel\":0,\"lsregion\":0,\"lscc\":10,\"lsccDesc\":\"กรุงเทพมหานคร\",\"lsrcode\":\"1001\",\"lsrcodeDesc\":\"ท้องถิ่นเขตพระนคร\",\"lsaa\":0,\"lsaaDesc\":\" \",\"lstt\":0,\"lsttDesc\":\" \",\"lsmm\":0,\"lsmmDesc\":\" \",\"lsyymm\":65\n",
      "--- Fetching HOUSING: yymm 6501-6512, cc=10\n",
      "  STATUS: 200\n",
      "  RAW (first 200 chars): [{\"lstrLevel\":0,\"lsregion\":0,\"lscc\":10,\"lsccDesc\":\"กรุงเทพมหานคร\",\"lsrcode\":\"1001\",\"lsrcodeDesc\":\"ท้องถิ่นเขตพระนคร\",\"lsaa\":0,\"lsaaDesc\":\" \",\"lstt\":0,\"lsttDesc\":\" \",\"lsmm\":0,\"lsmmDesc\":\" \",\"lsyymm\":65\n",
      "\n",
      "--- Fetching POPULATION: yymm 6601-6612, cc=10\n",
      "  STATUS: 200\n",
      "  RAW (first 200 chars): [{\"lstrLevel\":0,\"lsregion\":0,\"lscc\":10,\"lsccDesc\":\"กรุงเทพมหานคร\",\"lsrcode\":\"1001\",\"lsrcodeDesc\":\"ท้องถิ่นเขตพระนคร\",\"lsaa\":0,\"lsaaDesc\":\" \",\"lstt\":0,\"lsttDesc\":\" \",\"lsmm\":0,\"lsmmDesc\":\" \",\"lsyymm\":66\n",
      "--- Fetching HOUSING: yymm 6601-6612, cc=10\n",
      "  STATUS: 200\n",
      "  RAW (first 200 chars): [{\"lstrLevel\":0,\"lsregion\":0,\"lscc\":10,\"lsccDesc\":\"กรุงเทพมหานคร\",\"lsrcode\":\"1001\",\"lsrcodeDesc\":\"ท้องถิ่นเขตพระนคร\",\"lsaa\":0,\"lsaaDesc\":\" \",\"lstt\":0,\"lsttDesc\":\" \",\"lsmm\":0,\"lsmmDesc\":\" \",\"lsyymm\":66\n",
      "\n",
      "--- Fetching POPULATION: yymm 6701-6712, cc=10\n",
      "  STATUS: 200\n",
      "  RAW (first 200 chars): [{\"lstrLevel\":0,\"lsregion\":0,\"lscc\":10,\"lsccDesc\":\"กรุงเทพมหานคร\",\"lsrcode\":\"1001\",\"lsrcodeDesc\":\"ท้องถิ่นเขตพระนคร\",\"lsaa\":0,\"lsaaDesc\":\" \",\"lstt\":0,\"lsttDesc\":\" \",\"lsmm\":0,\"lsmmDesc\":\" \",\"lsyymm\":67\n",
      "--- Fetching HOUSING: yymm 6701-6712, cc=10\n",
      "  STATUS: 200\n",
      "  RAW (first 200 chars): [{\"lstrLevel\":0,\"lsregion\":0,\"lscc\":10,\"lsccDesc\":\"กรุงเทพมหานคร\",\"lsrcode\":\"1001\",\"lsrcodeDesc\":\"ท้องถิ่นเขตพระนคร\",\"lsaa\":0,\"lsaaDesc\":\" \",\"lstt\":0,\"lsttDesc\":\" \",\"lsmm\":0,\"lsmmDesc\":\" \",\"lsyymm\":67\n",
      "\n",
      "--- Fetching POPULATION: yymm 6801-6812, cc=10\n",
      "  STATUS: 200\n",
      "  RAW (first 200 chars): [{\"lstrLevel\":0,\"lsregion\":0,\"lscc\":10,\"lsccDesc\":\"กรุงเทพมหานคร\",\"lsrcode\":\"1001\",\"lsrcodeDesc\":\"ท้องถิ่นเขตพระนคร\",\"lsaa\":0,\"lsaaDesc\":\" \",\"lstt\":0,\"lsttDesc\":\" \",\"lsmm\":0,\"lsmmDesc\":\" \",\"lsyymm\":68\n",
      "--- Fetching HOUSING: yymm 6801-6812, cc=10\n",
      "  STATUS: 200\n",
      "  RAW (first 200 chars): [{\"lstrLevel\":0,\"lsregion\":0,\"lscc\":10,\"lsccDesc\":\"กรุงเทพมหานคร\",\"lsrcode\":\"1001\",\"lsrcodeDesc\":\"ท้องถิ่นเขตพระนคร\",\"lsaa\":0,\"lsaaDesc\":\" \",\"lstt\":0,\"lsttDesc\":\" \",\"lsmm\":0,\"lsmmDesc\":\" \",\"lsyymm\":68\n",
      "\n",
      " API data fetched and cached to JSON files\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cookies = {\n",
    "    \"_ga_WPG9F4YRE3\": \"GS2.1.s1765033766$o1$g0$t1765033766$j60$l0$h0\",\n",
    "    \"_ga\": \"GA1.1.1399864746.1765033766\",\n",
    "    \"TS012f8194\": \"010214bde367a4be39fc7d733390be0576058f11ad2f47a6c577a3be26dc2c439a593fbc739960a059e82d87d4bf1e8caa2f6444df\"\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\",\n",
    "    \"Accept\": \"application/json\"\n",
    "}\n",
    "\n",
    "def call_dopa(url):\n",
    "    \"\"\"Call DOPA API\"\"\"\n",
    "    r = requests.get(url, cookies=cookies, headers=headers)\n",
    "    print(\"  STATUS:\", r.status_code)\n",
    "    print(\"  RAW (first 200 chars):\", r.text[:200])\n",
    "\n",
    "    try:\n",
    "        return r.json()\n",
    "    except:\n",
    "        print(\" JSON decode error\")\n",
    "        return None\n",
    "\n",
    "# Config\n",
    "begin = [6501, 6601, 6701,6801]\n",
    "end   = [6512, 6612, 6712,6812]\n",
    "cc    = [10]\n",
    "\n",
    "population_file = \"population_data.json\"\n",
    "housing_file = \"housing_data.json\"\n",
    "\n",
    "# Load or create\n",
    "try:\n",
    "    with open(population_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        population_data = json.load(f)\n",
    "    print(f\" - Loaded existing {population_file}\")\n",
    "except:\n",
    "    population_data = []\n",
    "    print(f\" - Creating new {population_file}\")\n",
    "\n",
    "try:\n",
    "    with open(housing_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        housing_data = json.load(f)\n",
    "    print(f\" - Loaded existing {housing_file}\")\n",
    "except:\n",
    "    housing_data = []\n",
    "    print(f\" - Creating new {housing_file}\")\n",
    "\n",
    "# Fetch data\n",
    "for b, e in zip(begin, end):\n",
    "    for province in cc:\n",
    "\n",
    "        # Population API\n",
    "        pop_url = (\n",
    "            \"https://stat.bora.dopa.go.th/stat/statnew/connectSAPI/stat_forward.php\"\n",
    "            f\"?API=/api/statpophouse/v1/statpop/list\"\n",
    "            f\"?action=43\"\n",
    "            f\"&yymmBegin={b}\"\n",
    "            f\"&yymmEnd={e}\"\n",
    "            f\"&statType=0&statSubType=999&subType=99\"\n",
    "            f\"&cc={province}\"\n",
    "        )\n",
    "\n",
    "        print(f\"\\n--- Fetching POPULATION: yymm {b}-{e}, cc={province}\")\n",
    "        pop_data = call_dopa(pop_url)\n",
    "\n",
    "        if pop_data:\n",
    "            population_data.append({\n",
    "                \"begin\": b,\n",
    "                \"end\": e,\n",
    "                \"cc\": province,\n",
    "                \"data\": pop_data\n",
    "            })\n",
    "\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        # Housing API\n",
    "        house_url = (\n",
    "            \"https://stat.bora.dopa.go.th/stat/statnew/connectSAPI/stat_forward.php\"\n",
    "            f\"?API=/api/statpophouse/v1/stathouse/list\"\n",
    "            f\"?action=33\"\n",
    "            f\"&yymmBegin={b}\"\n",
    "            f\"&yymmEnd={e}\"\n",
    "            f\"&statType=0&statSubType=999&subType=99\"\n",
    "            f\"&cc={province}\"\n",
    "        )\n",
    "\n",
    "        print(f\"--- Fetching HOUSING: yymm {b}-{e}, cc={province}\")\n",
    "        house_data = call_dopa(house_url)\n",
    "\n",
    "        if house_data:\n",
    "            housing_data.append({\n",
    "                \"begin\": b,\n",
    "                \"end\": e,\n",
    "                \"cc\": province,\n",
    "                \"data\": house_data\n",
    "            })\n",
    "\n",
    "        time.sleep(0.5)\n",
    "\n",
    "# Save JSON files (for caching/debugging)\n",
    "with open(population_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(population_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "with open(housing_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(housing_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n API data fetched and cached to JSON files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9c46f8",
   "metadata": {},
   "source": [
    "## 5. Build Lookup Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3a515a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area lookup: 50 records\n",
      "Population lookup: 2350 records\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def clean_province_name(name: str) -> str:\n",
    "    \"\"\"Clean province name by removing prefix\"\"\"\n",
    "    if not isinstance(name, str):\n",
    "        return name\n",
    "    \n",
    "    # Remove \"จังหวัด\" prefix\n",
    "    clean = re.sub(r\"^จังหวัด\", \"\", name).strip()\n",
    "    return clean\n",
    "\n",
    "\n",
    "\n",
    "def clean_district_name(name: str) -> str:\n",
    "    \"\"\"Clean district name by removing prefixes\"\"\"\n",
    "    if not isinstance(name, str):\n",
    "        return name\n",
    "\n",
    "    prefixes = [\n",
    "        r\"^อำเภอ\",\n",
    "        r\"^ท้องถิ่นเขต\",\n",
    "        r\"^เขต\"\n",
    "    ]\n",
    "\n",
    "    clean = name.strip()\n",
    "    for p in prefixes:\n",
    "        clean = re.sub(p, \"\", clean).strip()\n",
    "\n",
    "    return clean\n",
    "# Build area dictionary from scraped data\n",
    "area_dict = {}\n",
    "for row in area_rows:\n",
    "    province = row[\"province\"]\n",
    "    district = clean_district_name(row[\"district\"])\n",
    "    area_km2 = row[\"area_km2\"]\n",
    "    \n",
    "    key = (province, district)\n",
    "    area_dict[key] = area_km2\n",
    "\n",
    "print(f\"Area lookup: {len(area_dict)} records\")\n",
    "\n",
    "# Build population dictionary\n",
    "population_dict = {}\n",
    "\n",
    "for entry in population_data:\n",
    "    for row in entry.get(\"data\", []):\n",
    "        \n",
    "        district_raw = row.get(\"lsrcodeDesc\", \"\")\n",
    "        \n",
    "        if \"ท้องถิ่นเทศบาล\" in district_raw:\n",
    "            continue\n",
    "        \n",
    "        district_clean = clean_district_name(district_raw)\n",
    "        \n",
    "        lsyymm = str(row.get(\"lsyymm\", \"\"))\n",
    "        year = lsyymm[:2]\n",
    "        month = lsyymm[2:]\n",
    "        \n",
    "        province_raw = row.get(\"lsccDesc\", \"\")\n",
    "        province = clean_province_name(province_raw)  # Clean province name\n",
    "        total_pop = row.get(\"lssumtotTot\", \"\")\n",
    "        \n",
    "        key = (province, district_clean, year, month)\n",
    "        population_dict[key] = total_pop\n",
    "\n",
    "print(f\"Population lookup: {len(population_dict)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3f905b",
   "metadata": {},
   "source": [
    "## 6. Combine All Scraped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d8f3c864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined 18642 records\n",
      "Sorted by province, district, year, month\n",
      "Saved to clean_combined_data.csv\n",
      "Total rows: 18642\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def clean_province_name(name: str) -> str:\n",
    "    \"\"\"Clean province name by removing prefix\"\"\"\n",
    "    if not isinstance(name, str):\n",
    "        return name\n",
    "    \n",
    "    # Remove \"จังหวัด\" prefix\n",
    "    clean = re.sub(r\"^จังหวัด\", \"\", name).strip()\n",
    "    return clean\n",
    "\n",
    "combined_rows = []\n",
    "\n",
    "for entry in housing_data:\n",
    "    for row in entry.get(\"data\", []):\n",
    "        \n",
    "        district_raw = row.get(\"lsrcodeDesc\", \"\")\n",
    "        \n",
    "        if \"ท้องถิ่นเทศบาล\" in district_raw:\n",
    "            continue\n",
    "        \n",
    "        district_clean = clean_district_name(district_raw)\n",
    "        \n",
    "        lsyymm = str(row.get(\"lsyymm\", \"\"))\n",
    "        year = lsyymm[:2]\n",
    "        month = lsyymm[2:]\n",
    "        \n",
    "        province_raw = row.get(\"lsccDesc\", \"\")\n",
    "        province = clean_province_name(province_raw)  # Clean province name\n",
    "        housing = row.get(\"lssumnotTermDate\", \"\")\n",
    "        \n",
    "        # Get matching data\n",
    "        key_pop = (province, district_clean, year, month)\n",
    "        key_landfill = (province, district_clean, year)\n",
    "        key_area = (province, district_clean)\n",
    "        \n",
    "        total_population = population_dict.get(key_pop, \"\")\n",
    "        area_km2 = area_dict.get(key_area, \"\")\n",
    "        \n",
    "        # Calculate densities\n",
    "        population_density = \"\"\n",
    "        housing_density = \"\"\n",
    "        \n",
    "        if area_km2 and area_km2 != \"\":\n",
    "            try:\n",
    "                area_float = float(area_km2)\n",
    "                \n",
    "                if total_population and total_population != \"\":\n",
    "                    pop_float = float(total_population)\n",
    "                    population_density = f\"{pop_float / area_float:.2f}\"\n",
    "                \n",
    "                if housing and housing != \"\":\n",
    "                    house_float = float(housing)\n",
    "                    housing_density = f\"{house_float / area_float:.2f}\"\n",
    "            except (ValueError, ZeroDivisionError):\n",
    "                pass\n",
    "        \n",
    "        combined_rows.append({\n",
    "            \"province\": province,\n",
    "            \"district\": district_clean,\n",
    "            \"total_population\": total_population,\n",
    "            \"housing\": housing,\n",
    "            \"year\": year,\n",
    "            \"month\": month,\n",
    "            \"area_km2\": area_km2,\n",
    "            \"population_density\": population_density,\n",
    "            \"housing_density\": housing_density\n",
    "        })\n",
    "\n",
    "print(f\"Combined {len(combined_rows)} records\")\n",
    "\n",
    "# Sort\n",
    "combined_rows.sort(key=lambda x: (x[\"province\"], x[\"district\"], x[\"year\"], x[\"month\"]))\n",
    "print(f\"Sorted by province, district, year, month\")\n",
    "\n",
    "def escape_csv_field(field):\n",
    "    \"\"\"Escape CSV field\"\"\"\n",
    "    field = str(field)\n",
    "    if ',' in field or '\"' in field or '\\n' in field:\n",
    "        field = '\"' + field.replace('\"', '\"\"') + '\"'\n",
    "    return field\n",
    "\n",
    "output_csv = \"clean_combined_data.csv\"\n",
    "\n",
    "with open(output_csv, \"w\", encoding=\"utf-8-sig\") as f:\n",
    "    # Write header\n",
    "    f.write(\"province,district,total_population,housing,year,month,area_km2,population_density,housing_density\\n\")\n",
    "    \n",
    "    # Write data rows\n",
    "    for row in combined_rows:\n",
    "        line = (\n",
    "            f\"{escape_csv_field(row['province'])},\"\n",
    "            f\"{escape_csv_field(row['district'])},\"\n",
    "            f\"{escape_csv_field(row['total_population'])},\"\n",
    "            f\"{escape_csv_field(row['housing'])},\"\n",
    "            f\"{escape_csv_field(row['year'])},\"\n",
    "            f\"{escape_csv_field(row['month'])},\"\n",
    "            f\"{escape_csv_field(row['area_km2'])},\"\n",
    "            f\"{escape_csv_field(row['population_density'])},\"\n",
    "            f\"{escape_csv_field(row['housing_density'])}\\n\"\n",
    "        )\n",
    "        f.write(line)\n",
    "\n",
    "print(f\"Saved to {output_csv}\")\n",
    "print(f\"Total rows: {len(combined_rows)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
